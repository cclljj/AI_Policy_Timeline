[
    {
      "Date": "January 2025",
      "Event": "Executive Order: Removing Barriers to American Leadership in Artificial Intelligence",
      "Description": "On January 23, 2025, an executive order titled 'Removing Barriers to American Leadership in Artificial Intelligence' was issued to bolster U.S. dominance in AI. This policy aims to eliminate regulatory obstacles that hinder AI innovation, emphasizing the development of AI systems free from ideological bias to promote human flourishing, economic competitiveness, and national security. It mandates the creation of an AI action plan within 180 days, involving key offices such as the Assistant to the President for Science and Technology and the Special Advisor for AI and Crypto. The order also requires an immediate review of actions under the previous Executive Order 14110 (October 2023) and directs the Office of Management and Budget (OMB) to revise specific memoranda within 60 days to align with this new policy. This executive action underscores a strategic shift toward deregulation, aiming to accelerate AI development while ensuring alignment with American values. It reflects the government's recognition of AI's critical role in maintaining economic and security advantages globally, though its long-term impact depends on the specifics of the action plan and subsequent implementations.",
      "Type": "USA"
    },
    {
      "Date": "January 2023",
      "Event": "AI Risk Management Framework (RMF)",
      "Description": "The National Institute of Standards and Technology (NIST) released the AI Risk Management Framework (RMF) on January 26, 2023, as a voluntary tool to manage risks associated with AI. This framework guides organizations in incorporating trustworthiness into AI design, development, use, and evaluation, addressing risks to individuals, organizations, and society. Developed through a transparent, consensus-driven process with public input, the RMF aligns with other AI risk management efforts. It includes companion resources like the AI RMF Playbook, Roadmap, and Crosswalk, and is supported by the Trustworthy and Responsible AI Resource Center, launched in March 2023. A Generative AI Profile, released in July 2024, addresses specific risks of generative AI technologies. The RMF is pivotal for promoting ethical AI practices, offering practical guidance for organizations to mitigate potential harms while fostering innovation. Its voluntary nature encourages broad adoption across sectors, making it a cornerstone of responsible AI governance in the U.S.",
      "Type": "USA"
    },
    {
      "Date": "May 2023",
      "Event": "Establishment of Seven New National Artificial Intelligence Research Institutes",
      "Description": "In May 2023, the National Science Foundation (NSF) announced a $140 million investment to establish seven new National Artificial Intelligence Research Institutes (AI Institutes). These institutes aim to advance fundamental AI research while addressing societal challenges in areas such as ethical AI, cybersecurity, climate change, brain science, and education. Each institute, funded up to $20 million over five years, involves collaborations among multiple universities to tackle large-scale, long-term AI challenges. This initiative aligns with the National Artificial Intelligence Research and Development Strategic Plan, emphasizing long-term investments in AI to maintain U.S. technical leadership. By fostering multidisciplinary teams, the institutes support the development of a diverse AI workforce and address critical issues like trustworthy AI systems and environmental sustainability. This policy underscores the government’s commitment to strengthening AI research infrastructure, ensuring the U.S. remains competitive globally while addressing societal needs through innovative AI applications.",
      "Type": "USA"
    },
    {
      "Date": "December 2020",
      "Event": "AI in Government Act of 2020",
      "Description": "Enacted in December 2020 as part of the Consolidated Appropriations Act, 2021, the AI in Government Act established the AI Center of Excellence within the General Services Administration (GSA). This center provides guidance to federal agencies on responsible AI adoption, enhancing efficiency and public service delivery. The Act directed the Office of Management and Budget (OMB) to issue a memorandum outlining AI acquisition and application policies, identifying best practices for risk mitigation, and highlighting opportunities to improve agency operations and public services. It also required the Office of Personnel Management to submit a workforce development plan for AI within 120 days. This legislation institutionalizes AI governance within the federal government, ensuring ethical and effective AI use. By creating a centralized resource for AI expertise, the Act fosters a coordinated approach to AI integration, balancing innovation with accountability to maintain public trust.",
      "Type": "USA"
    },
    {
        "Date": "December 2017",
        "Event": "Master Plan for Intelligent Information Society",
        "Description": "In December 2017, South Korea launched the Master Plan for Intelligent Information Society to prepare for the Fourth Industrial Revolution. This plan focused on creating a national data management system, opening public data, and supporting AI research. It also introduced big data learning programs and emphasized data governance to balance innovation with privacy rights. This policy set the foundation for South Korea's future AI initiatives.",
        "Type": "Korea"
      },
      {
        "Date": "December 2019",
        "Event": "National AI Strategy",
        "Description": "Released in December 2019, the National AI Strategy aims to make South Korea a global AI leader. It focuses on building AI infrastructure, advancing technology, and developing a skilled workforce. The strategy also emphasizes ethical AI use, ensuring that AI development aligns with societal values and benefits the public.",
        "Type": "Korea"
      },
      {
        "Date": "January 2025",
        "Event": "AI Basic Act",
        "Description": "Promulgated in January 2025, the AI Basic Act is South Korea’s first comprehensive AI law, effective from January 2026. It regulates high-impact AI systems, supports innovation, and establishes governance structures to ensure trustworthy AI. This act reflects South Korea's commitment to balancing AI advancement with ethical considerations and public trust.",
        "Type": "Korea"
      },
      {
        "Date": "May 2017",
        "Event": "Launch of AI Singapore",
        "Description": "AI Singapore, launched in May 2017, is a national program to position Singapore as a global AI leader. It fosters collaboration among research institutions, start-ups, and companies to drive use-inspired AI research, knowledge creation, and tool development. Key initiatives include the 100E Programme, supporting companies in building AI products; the AI Apprenticeship Programme, developing local talent; LearnAI, offering educational resources for all ages; AI4SME, aiding small businesses; and Project SEA-LION, advancing multilingual AI. AI Singapore prioritizes ethical AI, researching fairness, accountability, and safety, with tools open-sourced under Apache 2.0. By building a robust AI ecosystem, it drives technological advancement and economic growth while ensuring responsible AI use, aligning with Singapore’s vision of a trusted AI hub.",
        "Type": "Singapore"
      },
      {
        "Date": "January 2019",
        "Event": "Release of Model AI Governance Framework",
        "Description": "The Model AI Governance Framework, released in January 2019 by Singapore’s PDPC and IMDA, is a voluntary guideline for ethical AI deployment. It covers internal governance, human involvement in AI decisions, operations management, and stakeholder communication, emphasizing transparency, fairness, and human-centricity. The second edition (January 2020) added tools like ISAGO, enhancing practical application. Flexible across industries, it aligns with global standards (e.g., EU, OECD), fostering trust in AI systems. By guiding organizations to adopt responsible practices, it strengthens Singapore’s reputation as a leader in AI governance, balancing innovation with accountability.",
        "Type": "Singapore"
      },
      {
        "Date": "November 2019",
        "Event": "Release of Singapore's First National AI Strategy",
        "Description": "Singapore’s National AI Strategy, launched in November 2019, aims to make Singapore a global AI leader by 2030. It focuses on scalable AI solutions in sectors like healthcare and logistics, with pillars including national AI projects (e.g., Intelligent Freight Planning), ecosystem enablers (training 25,000 professionals by 2025), and a human-centric approach. Updated as NAIS 2.0 in 2023, it emphasizes systems thinking and global collaboration. By addressing workforce adaptation and governance risks, the strategy drives economic growth, enhances public services, and ensures ethical AI use, positioning Singapore as a trusted AI hub.",
        "Type": "Singapore"
      },
      {
        "Date": "May 2022",
        "Event": "Launch of AI Verify",
        "Description": "AI Verify, launched on 25 May 2022 by IMDA and PDPC, is an AI governance testing framework assessing systems against 11 global principles, including fairness and accountability. Developed with AWS, Google, and Microsoft, it standardizes testing, offering actionable steps and evidence requirements. Open-sourced in June 2023 and updated for generative AI in May 2025, it aligns with frameworks like NIST’s AI RMF. Targeting developers and auditors, AI Verify ensures responsible AI use, fostering trust. It supports Singapore’s trusted AI ecosystem, setting a global benchmark for ethical AI governance.",
        "Type": "Singapore"
      },
      {
        "Date": "January 2024",
        "Event": "Public Consultation on Draft Model AI Governance Framework for Generative AI",
        "Description": "On 16 January 2024, IMDA and the AI Verify Foundation launched a public consultation on the Draft Model AI Governance Framework for Generative AI. Addressing challenges like misinformation, it proposes nine governance dimensions: accountability, data, trusted development, incident reporting, testing, security, content provenance, safety R&D, and public good. Building on existing AI policies, it balances innovation with responsibility. The consultation ensures stakeholder input for a practical, global framework. Once finalized, it will guide ethical generative AI deployment, reinforcing Singapore’s leadership in AI governance.",
        "Type": "Singapore"
      },
      {
        "Date": "February 2025",
        "Event": "Announcement of Enterprise Compute Initiative in Budget 2025",
        "Description": "Announced on 18 February 2025 in Budget 2025, the Enterprise Compute Initiative allocates $150 million to support enterprises in adopting AI. Eligible businesses can partner with cloud providers for AI tools, computing power, and consultancy, enabling tailored solutions. Aligned with the National AI Strategy, it strengthens Singapore’s AI ecosystem, particularly for SMEs, enhancing competitiveness and economic growth. By reducing adoption barriers, it drives business transformation. The initiative’s success depends on enterprise engagement, but government support positions Singapore as an AI innovation hub.",
        "Type": "Singapore"
      },
      {
        "Date": "July 2017",
        "Event": "New Generation Artificial Intelligence Development Plan",
        "Description": "The 'New Generation Artificial Intelligence Development Plan,' issued by China’s State Council in July 2017, is a foundational policy aimed at establishing China as the global leader in AI by 2030. It outlines three key milestones: by 2020, achieving parity with global AI leaders, growing the AI industry to over 150 billion RMB, and establishing initial ethical norms; by 2025, achieving major breakthroughs in AI theories and technologies, expanding the AI industry to 400 billion RMB, and developing comprehensive AI laws and standards; and by 2030, becoming the world’s primary AI innovation center with a 1 trillion RMB AI industry. The plan emphasizes advancements in basic theories, key technologies, innovation platforms, and talent development, while fostering a smart economy, intelligent society, and military-civilian integration. It has spurred significant government investment, estimated in the tens of billions of dollars, and fostered a competitive AI ecosystem through innovation clusters and international partnerships. The plan also prioritizes reducing dependence on foreign technology and addressing ethical concerns, reflecting China’s ambition to lead in AI while ensuring alignment with national security and societal values. Its implementation has positioned China as a major player in AI, though challenges remain in achieving all its ambitious goals.",
        "Type": "China"
      },
      {
        "Date": "March 2021",
        "Event": "14th Five-Year Plan for National Economic and Social Development",
        "Description": "The '14th Five-Year Plan for National Economic and Social Development,' adopted in March 2021, identifies AI as one of seven priority areas for technological breakthroughs. It sets a yearly 7% growth target for R&D expenditure, with a significant focus on AI to drive innovation and economic transformation. The plan includes initiatives like the Action Plan for High-Quality Computing Power Infrastructure, aiming to increase China’s computing power to 300 EFLOPS by 2025 (from 197 EFLOPS in 2023, ranking second globally). It also supports local efforts, such as Shanghai’s target for 1,000 high-quality datasets and Shenzhen’s public data platform, to bolster AI research and applications. The plan integrates AI into sectors like healthcare, education, and manufacturing, aiming to improve efficiency, enhance public services, and address societal challenges such as aging populations and environmental sustainability. By embedding AI in its five-year planning cycle, China ensures systematic support for AI innovation, aligning with broader goals of technological self-reliance and reducing dependence on foreign technology. The plan’s focus on computing power and data infrastructure is critical for advancing AI capabilities, positioning China to compete globally in AI development and deployment.",
        "Type": "China"
      },
      {
        "Date": "September 21, 2021",
        "Event": "New Generation Artificial Intelligence Code of Ethics",
        "Description": "Released on September 21, 2021, by China’s Ministry of Science and Technology, the 'New Generation Artificial Intelligence Code of Ethics' provides a foundational ethical framework for AI development and use in China. Developed by the National New Generation Artificial Intelligence Governance Professional Committee, the code covers the entire AI lifecycle, offering guidance to individuals, organizations, and institutions. It emphasizes six core principles: enhancing human well-being, promoting fairness and justice, protecting privacy and security, ensuring controllability and trustworthiness, strengthening accountability, and improving ethical literacy. The code advocates for AI to support sustainable development, respect human rights, and prevent discrimination, with specific measures for data protection, transparency, and accountability. It includes R&D specifications for data storage and use, market regulations, and organizational guidelines for ethical AI practices. While voluntary, the code has influenced subsequent AI policies and reflects China’s commitment to responsible AI development. It also encourages international cooperation on AI ethics and public education on AI responsibilities, positioning China as a proactive leader in ethical AI governance. The code’s emphasis on aligning AI with societal values and human rights is crucial for fostering public trust and ensuring AI’s positive impact on society.",
        "Type": "China"
      },
      {
        "Date": "August 15, 2023",
        "Event": "Interim Measures for the Management of Generative Artificial Intelligence Services",
        "Description": "The 'Interim Measures for the Management of Generative Artificial Intelligence Services,' enacted on August 15, 2023, is China’s first specific regulation targeting generative AI services. Issued by multiple government bodies, including the Cyberspace Administration of China, it applies to all providers of generative AI services within China, regardless of their location. The regulation mandates compliance with data processing, intellectual property rights, and user consent, requiring security assessments and regulatory filings for AI services. It emphasizes content moderation, user protection, and cooperation with government inspections, with penalties for non-compliance. The measures also introduced data labeling rules (effective September 1, 2025) and national cybersecurity standards for generative AI (effective November 1, 2025), ensuring that AI-generated content is identifiable and secure. The regulation balances innovation with control, allowing AI development while ensuring alignment with national security and societal values. It has led to increased scrutiny of AI companies, with some facing penalties for failing to meet compliance standards. The measures reflect China’s proactive approach to governing emerging technologies, setting a precedent for other nations while fostering a controlled environment for AI innovation.",
        "Type": "China"
      },
      {
        "Date": "June 2023",
        "Event": "Draft Comprehensive Artificial Intelligence Law",
        "Description": "In June 2023, China’s State Council announced plans to draft a comprehensive Artificial Intelligence Law, marking a significant step toward unified AI governance. A preliminary draft was circulated among scholars by May 2024, focusing on regulating AI development, provision, and use while balancing innovation with national security and public interests. The law is expected to address key issues such as liability for AI misuse, intellectual property protections for AI-generated content, and data usage for training AI models. It builds on existing regulations like the Interim Measures for Generative AI, aiming to create a cohesive legal framework for all AI applications. Experts note challenges in defining AI and the potential need for sector-specific laws to address diverse applications. The law’s development reflects China’s ambition to lead in AI regulation, potentially influencing global standards. Once finalized, it will provide a comprehensive governance structure, ensuring that AI development aligns with China’s strategic goals while fostering innovation and protecting societal interests. The law’s progress is closely watched, as it could set a global benchmark for AI legislation.",
        "Type": "China"
      },
      {
        "Date": "2019",
        "Event": "Social Principles of Human-Centric AI",
        "Description": "In 2019, the Japanese government released the *Social Principles of Human-Centric AI*, establishing an ethical foundation for AI development and use in Japan. This document outlines three core philosophies: human dignity, diversity and inclusion, and sustainability. Human dignity ensures AI respects fundamental human rights and individual autonomy. Diversity and inclusion mandate that AI systems accommodate varied human experiences, preventing discrimination and promoting fairness. Sustainability requires AI to support long-term societal and environmental goals. These principles align with international efforts, such as the OECD AI Principles, which Japan supports, reflecting its commitment to global ethical standards. The document stresses that AI should enhance, not replace, human decision-making, advocating a \"human-in-the-loop\" approach, particularly in critical sectors like healthcare and transportation. It calls for collaboration among industry, academia, and civil society to incorporate diverse perspectives, emphasizing transparency and accountability in AI systems so users can understand and contest decisions. The *Social Principles* have shaped subsequent Japanese AI policies, including the AI Guidelines for Business and international initiatives like the Hiroshima AI Process. They underpin Japan’s vision of \"Society 5.0,\" a human-centered society where technology addresses societal challenges and enhances quality of life. By prioritizing ethical and inclusive AI, Japan seeks to build public trust and ensure equitable benefits, setting a precedent for responsible AI governance domestically and globally. This foundational policy reflects Japan’s cautious yet progressive stance on integrating AI into society while safeguarding human values.",
        "Type": "Japan"
      },
      {
        "Date": "2023",
        "Event": "Hiroshima AI Process",
        "Description": "In 2023, during its G7 presidency, Japan spearheaded the *Hiroshima AI Process*, an international effort to promote trustworthy AI systems. The initiative concluded with the Hiroshima AI Process Comprehensive Policy Framework in December 2023, endorsed by G7 nations. This framework includes guiding principles and a code of conduct, emphasizing that AI must uphold human rights, democracy, and the rule of law, fostering ethical AI development worldwide. The guiding principles prioritize transparency, accountability, and fairness in AI systems, addressing risks like bias, privacy breaches, and security threats. The code of conduct offers practical guidance for developers, providers, and users to implement these principles effectively. Japan’s leadership in this process highlights its role in global AI governance, bridging diverse regulatory perspectives—such as the EU’s strict approach and the U.S.’s innovation focus—through collaboration. The *Hiroshima AI Process* has influenced Japan’s domestic policies by reinforcing the need to align with international standards, enhancing its credibility in global AI discussions. It positions Japan as a mediator in international AI ethics, fostering future collaborations. The framework’s lasting impact lies in its promotion of a unified approach to AI governance, encouraging nations to adopt consistent, responsible practices. For Japan, it underscores a commitment to advancing AI innovation while ensuring ethical oversight, amplifying its voice in shaping the global AI landscape.",
        "Type": "Japan"
      },
      {
        "Date": "April 2024",
        "Event": "AI Guidelines for Business Ver1.0",
        "Description": "On April 19, 2024, Japan’s Ministry of Economy, Trade, and Industry (METI) and Ministry of Internal Affairs and Communications released the *AI Guidelines for Business Ver1.0*. These voluntary guidelines provide clear, accessible advice for AI developers, providers, and users, aligning with international trends in AI governance. They reflect Japan’s soft law approach, encouraging responsible AI practices without mandatory regulations. The guidelines advocate a risk-based approach, urging stakeholders to identify and mitigate AI-related risks, such as bias or misuse. They stress transparency, fairness, and accountability, recommending mechanisms for explaining and auditing AI decisions. A key feature is agile governance, where stakeholders continuously analyze risks, set goals, and evaluate systems to adapt to technological advances. Practical steps, like AI impact assessments and stakeholder engagement, aim to balance innovation with responsibility. Though not legally binding, adherence to these guidelines could influence legal outcomes in AI disputes, as they embody widely accepted principles. Replacing three prior guidelines, they streamline Japan’s AI governance strategy, supporting an AI-friendly environment that respects societal rights. Compatible with global frameworks, they enhance cross-border collaboration. The *AI Guidelines* demonstrate Japan’s intent to foster innovation while ensuring ethical AI deployment, particularly aiding businesses in navigating complex AI challenges responsibly.",
        "Type": "Japan"
      },
      {
        "Date": "February 2025",
        "Event": "Interim Report of the AI Policy Study Group",
        "Description": "Published on February 4, 2025, by the Cabinet Office, the *Interim Report of the AI Policy Study Group* outlines Japan’s evolving AI regulatory strategy. It proposes a light-touch framework, relying on existing sector-specific laws rather than new AI-specific regulations, reflecting a preference for technological neutrality and innovation over restrictive rules. This approach contrasts with the EU’s stricter regulations, aligning more with the U.S.’s innovation-driven model. The report encourages businesses to adopt voluntary risk-mitigation measures, promoting proactive responsibility. The government commits to monitoring AI risks and responding as needed, proposing a strategic leadership body to collect data, foster cooperation, and manage major incidents. This body, outlined in suggested legislation, avoids legal penalties, emphasizing collaboration over enforcement. Consistent with Japan’s innovation-friendly stance, the report supports startups and businesses by reducing compliance burdens, with the government aiding responsible AI adoption. This agile, multi-stakeholder approach aims to attract investment while addressing societal concerns, positioning Japan as a leader in flexible AI governance. The recommendations are poised to guide future policies, influencing both domestic and international AI discussions by showcasing a balanced, practical model for managing AI’s growth and risks.",
        "Type": "Japan"
      },
      {
        "Date": "February 2025",
        "Event": "Bill on the Promotion of Research, Development and Utilization of Artificial Intelligence-Related Technologies",
        "Description": "Submitted to the Diet on February 28, 2025, the *Bill on the Promotion of Research, Development and Utilization of Artificial Intelligence-Related Technologies* marks Japan’s first comprehensive AI law. It seeks to advance AI research, development, and use while ensuring businesses align with government initiatives, reflecting Japan’s dual focus on innovation and responsibility. The bill mandates private entities to \"cooperate\" with government policies—potentially through information sharing or guideline adherence—without imposing penalties, favoring collaboration. It also requires the government to investigate AI misuse cases harming rights or interests, enabling measures like guidance or public disclosure of offenders to protect citizens and promote accountability. While its geographic scope isn’t explicit, the bill may apply to foreign firms, signaling Japan’s aim to influence global AI standards. If passed, it would strengthen Japan’s leadership in AI governance, offering a model for balancing innovation and oversight. This proactive legislation highlights Japan’s strategy to harness AI’s economic and societal benefits while addressing its challenges, reinforcing its position in the global AI policy arena.",
        "Type": "Japan"
      },
      {
        "Date": "2018",
        "Event": "National Artificial Intelligence Strategy",
        "Description": "Launched in 2018 by NITI Aayog, the National Artificial Intelligence Strategy is India’s first comprehensive policy framework for AI. It aims to position India as a global leader by 2035, focusing on sectors like healthcare, education, agriculture, smart cities, and transportation. The strategy emphasizes developing high-quality datasets, ensuring data protection, and strengthening cybersecurity. It promotes an inclusive approach, ensuring AI benefits reach all societal segments. Key components include establishing AI centers of excellence, fostering public-private partnerships, and encouraging research in AI technologies. It also stresses ethical AI practices, transparency, fairness, and accountability, identifying flagship projects like AI for healthcare diagnostics and precision agriculture. The strategy advocates for indigenous AI development to reduce foreign dependence and protect national security, addressing AI’s impact on employment through workforce transition and lifelong learning. It highlights international collaboration through platforms like the Global Partnership on Artificial Intelligence (GPAI) and encourages open-source AI models. The strategy outlines a phased approach: short-term (2018-2022) for foundational capabilities, medium-term (2023-2027) for scaling applications, and long-term (2028-2035) for global leadership. It includes measures for AI entrepreneurship, regulatory frameworks, and public awareness, aligning AI with national priorities and societal needs.",
        "Type": "India"
      },
      {
        "Date": "2020",
        "Event": "Responsible AI for Social Empowerment (RAISE)",
        "Description": "Launched in 2020, the Responsible AI for Social Empowerment (RAISE) initiative promotes ethical AI development, aligning with the National Development Agenda 2030 and SDGs. It focuses on leveraging AI for social good, addressing challenges like poverty, healthcare access, and education. RAISE encourages the adoption of AI in public services, ensuring inclusivity and accessibility, particularly for marginalized communities. The initiative supports the development of AI applications in areas like disease detection, agricultural productivity, and linguistic diversity, fostering innovation while ensuring ethical standards. It emphasizes collaboration between government, industry, and academia to create AI solutions that respect human rights and promote equity. RAISE also addresses AI’s societal impact, advocating for policies that mitigate job displacement and support reskilling. By promoting responsible AI, RAISE aims to build public trust and ensure that AI contributes positively to India’s development goals. The initiative has been instrumental in shaping subsequent AI policies, reinforcing India’s commitment to human-centric AI governance and setting a model for developing nations.",
        "Type": "India"
      },
      {
        "Date": "February 2021",
        "Event": "Principles for Responsible AI",
        "Description": "Released by NITI Aayog in February 2021, the Principles for Responsible AI provide a framework for ethical AI development and deployment. These principles guide policymakers, developers, and users, ensuring AI systems are developed and used responsibly. The seven key principles include safety and reliability, fairness and non-discrimination, privacy and security, transparency and explainability, accountability, promotion of positive human values, and inclusivity. Safety ensures AI systems do not cause harm, while fairness prevents bias and discrimination. Privacy protects personal data, and transparency allows users to understand AI decisions. Accountability assigns responsibility for AI outcomes, and positive human values align AI with societal norms. Inclusivity ensures AI benefits all segments of society. The principles address societal impacts, such as employment effects and the need for reskilling programs. By adopting these principles, India aims to foster trust in AI technologies, serving as a foundation for future regulations and policies. They are categorized into system and societal considerations, focusing on technical aspects like decision-making and broader impacts like economic inequality, promoting a human-centric approach to AI governance.",
        "Type": "India"
      },
      {
        "Date": "May 26, 2022",
        "Event": "Draft National Data Governance Framework Policy (NDGFP)",
        "Description": "Released on May 26, 2022, the Draft National Data Governance Framework Policy (NDGFP) is crucial for India’s data ecosystem, supporting AI development. It aims to modernize government data management, promoting data sharing while protecting privacy. The policy establishes the India Data Management Office (IDMO) to oversee data governance and the India Datasets Platform (IDP) for accessing non-personal datasets. It encourages private sector contributions, fostering innovation, and ensures compliance with data protection laws, promoting ethical data use. By providing structured access to anonymized data, it supports AI research and development, enabling informed decision-making and innovation. The policy balances data utility with privacy, setting standards for data quality and security, and facilitates international data flows, enhancing India’s global competitiveness in AI. It defines non-personal data, categorizing it into open, community, and closed datasets, with different access levels. The IDMO develops standards for data sharing, ensuring interoperability, while the IDP streamlines dataset access for researchers. It includes data anonymization techniques and promotes capacity building in data science and AI, driving innovation and economic growth while safeguarding individual rights.",
        "Type": "India"
      },
      {
        "Date": "2023",
        "Event": "India AI Mission",
        "Description": "Launched in 2023 by the Ministry of Electronics and Information Technology (MeitY), the India AI Mission is a flagship initiative with a $295 million budget over five years. It aims to create a comprehensive AI innovation ecosystem, focusing on developing indigenous AI technologies, building AI talent, and promoting applications for societal challenges. Key components include setting up AI centers of excellence, providing high-performance computing resources, and fostering collaboration between industry, academia, and government. The mission supports AI startups through funding and incubation, emphasizing responsible AI development aligned with ethical guidelines and international standards. It drives innovation in sectors like healthcare, agriculture, education, and smart cities, contributing to economic growth and social development. The mission includes the India Datasets Program for non-personal dataset access and plans a national AI portal for resources. It supports AI applications in regional languages, promoting inclusion, and focuses on capacity building through training programs. By investing in AI infrastructure and human capital, the India AI Mission positions India to compete globally, combining technology development, talent cultivation, and ethical considerations for a strong AI future.",
        "Type": "India"
      },
      {
        "Date": "2024",
        "Event": "Bhashini Initiative",
        "Description": "Launched in 2024, the Bhashini Initiative develops open-source natural language processing (NLP) models for India’s 22 official languages and dialects, breaking language barriers. It makes AI-powered language translation tools freely available, enhancing digital inclusion by empowering developers with NLP models and datasets. The initiative supports government services, education, healthcare, and e-commerce, making them accessible in regional languages, fostering innovation in AI-driven language technologies. It aligns with the National Education Policy 2020’s emphasis on mother tongue education and the National Language Translation Mission, promoting social equity and cultural preservation. Bhashini is developed collaboratively by government agencies, research institutions, and industry partners, creating large-scale multilingual datasets and deploying models through an open platform. It focuses on real-time translation, speech recognition, and synthesis in multiple languages, facilitating voice-based digital interactions. The open-source nature encourages community contributions, improving language coverage and bridging the digital divide, particularly in rural areas. Bhashini is a testament to India’s commitment to leveraging AI for social good, ensuring technological advancements benefit all citizens, irrespective of linguistic background.",
        "Type": "India"
      },
      {
        "Date": "March 2018",
        "Event": "National AI Strategy 'AI for humanity'",
        "Description": "In March 2018, President Emmanuel Macron unveiled France's National AI Strategy, 'AI for humanity,' based on a report by mathematician Cédric Villani. This strategy aims to position France as a global leader in AI by 2030, focusing on three main pillars: enhancing AI education and training, establishing an open data policy, and developing an ethical framework for AI. The government committed EUR 1.5 billion by 2022, with EUR 700 million dedicated to research. Key initiatives include improving AI skills through financial incentives and diversity programs, creating the Grande Ecole du Numérique for digital training, and setting up a public laboratory to study AI's impact on the labor market. The strategy also emphasizes open data policies, with a renewed focus in 2021, and the creation of the Pilot National Digital Ethics Committee in 2020 to ensure ethical AI development. Research and innovation are coordinated by Inria, with goals to strengthen the AI sector, accelerate spinoffs, and foster industry cooperation. The strategy includes plans for AI-specialized infrastructure like the Jean ZAY supercomputer and sectoral data hubs. Additionally, networking and collaboration efforts include the 3IA Institutes, trilateral research projects, and participation in GPAI. To attract foreign talent, policies were implemented to make France an attractive destination for AI researchers. Infrastructure development includes the Jean ZAY supercomputer and the CASD secure Data Hub, along with AI Challenges and sectoral data hubs. France is also involved in the GAIA-X project for digital sovereignty. This comprehensive approach ensures that France advances in AI technology while addressing ethical, societal, and economic implications.",
        "Type": "France"
      },
      {
        "Date": "November 2021",
        "Event": "National Strategy for AI",
        "Description": "In November 2021, as part of the 'France 2030' plan, France adopted its second-phase National Strategy for AI, building on the successes of the first phase (2018-2022). This strategy aims to further expand France's AI capabilities, focusing on three main objectives: enhancing the nation’s AI skills, establishing France as a leader in embedded and trustworthy AI, and accelerating AI integration into the economy. Key initiatives include the IA-Cluster, which transforms French training and research centers into global AI hubs, with goals to double the number of AI specialists by 2030 and elevate French institutions to top global rankings in AI. The IA-Booster program supports SMEs in adopting AI technologies, facilitating their digital transformation. The strategy is supported by significant public funding, part of the broader 'France 2030' investment plan, which allocates resources to strategic sectors including AI. This phase continues the commitment to ethical AI development and open data policies, ensuring that France remains at the forefront of AI innovation while addressing societal and ethical challenges. By fostering collaboration between public and private sectors, the strategy aims to create a robust AI ecosystem that drives economic growth and technological advancement. Additionally, the strategy plans to increase the number of AI-trained students to 3,700 annually by 2025 and invest in R&D for trustworthy and generative AI. The 'IA Booster France 2030' program specifically targets SMEs, helping them integrate AI into their operations. France also plans to co-finance a new exascale supercomputer with the EU by 2024-2025. A report from March 2024 recommends investing €27 billion in AI over five years to compete globally and achieve strategic autonomy in data centers and computing capabilities.",
        "Type": "France"
      },
      {
        "Date": "May 2023",
        "Event": "CNIL's AI Action Plan",
        "Description": "In May 2023, the French Data Protection Authority (CNIL) published its AI Action Plan, aimed at promoting the deployment of AI systems that respect individuals' privacy. This plan is a response to the rapid development of generative AI systems like ChatGPT and seeks to address the data protection challenges they pose. The CNIL has been proactive in addressing AI issues, having established an Artificial Intelligence Department in January 2023. The action plan is structured around four key objectives: understanding the functioning and impacts of AI systems on individuals, enabling and guiding the development of privacy-friendly AI, federating and supporting innovative players in the AI ecosystem, and auditing and controlling AI systems to protect personal data. Specific initiatives include publishing guidelines and 'how-to sheets' for AI development, focusing on issues such as data protection, bias, and discrimination. The CNIL also plans to extend its work to generative AIs and large language models, ensuring that AI development aligns with European values and prepares for the implementation of the European AI Regulation. By providing clear guidance and fostering collaboration, the CNIL aims to build trust in AI technologies while safeguarding fundamental rights. The CNIL's action plan includes detailed research and analysis through its Digital Innovation Laboratory (LINC), focusing on new data protection issues raised by AI, such as the protection of publicly available data against scraping and the rights of individuals concerning data used in AI training. The authority also plans to support the AI ecosystem by providing resources and fostering innovation that respects privacy. Enforcement actions are part of the plan, ensuring that AI systems comply with data protection regulations. The CNIL's efforts are crucial in preparing for the future European AI Regulation, which will set comprehensive standards for AI across the EU.",
        "Type": "France"
      },
      {
        "Date": "November 2018",
        "Event": "National AI Strategy",
        "Description": "In November 2018, Germany launched its National AI Strategy, a comprehensive framework to establish the country as a leading center for artificial intelligence while ensuring ethical and societal benefits. Developed by the Federal Ministry of Education and Research, the Federal Ministry for Economic Affairs and Energy, and the Federal Ministry of Labour and Social Affairs, it focuses on three goals: enhancing AI competitiveness, ensuring responsible AI development, and integrating AI ethically into society. Key initiatives include expanding the AI Campus for skill development, creating AI professorships, and providing vocational training. The strategy supports SMEs through Mittelstand 4.0 centres and funds AI start-ups via platforms like Gruenderplattform.de. Research efforts are bolstered by Competence Centres for AI Research, with funding doubled until 2022, and projects in healthcare (22 projects, EUR 50 million, 2020-2023) and agriculture (82 plans, EUR 92 million). International collaboration includes a Franco-German R&D network and participation in the Global Partnership on Artificial Intelligence (GPAI). The strategy increased AI funding from EUR 3 billion to EUR 5 billion by 2025. An interim report in November 2019 and an update in December 2020 refined these efforts, emphasizing human capital, innovation, and global cooperation. This strategy positions Germany as a leader in AI, balancing technological advancement with ethical considerations to address societal challenges and drive economic growth.",
        "Type": "Germany"
      },
      {
        "Date": "2021",
        "Event": "Amendment to German Works Constitution Act regarding AI",
        "Description": "In 2021, Germany amended its Works Constitution Act (Betriebsverfassungsgesetz) to address artificial intelligence (AI) in workplaces, specifically in Sections 80(3), 90(1) No.3, and 95(2a). This amendment enhances the rights of works councils—elected employee representatives—to ensure transparency and participation in AI implementation decisions. Works councils are entitled to comprehensive information about AI systems impacting working conditions, such as automated decision-making, surveillance technologies, or algorithms affecting personnel decisions. They can also consult external experts to assess AI’s technical and ethical implications, ensuring informed evaluations of job security, privacy, and workplace fairness. Where AI directly influences core employment aspects, like performance evaluations or dismissals, works councils have co-determination rights, requiring their agreement for implementation. This amendment aligns with Germany’s commitment to ethical AI, fostering a balance between technological innovation and labor rights. By empowering workers through information and consultation, it mitigates risks of AI misuse while promoting trust in workplace technologies. The policy reflects Germany’s broader strategy to integrate AI responsibly, ensuring social responsibility alongside economic benefits. It sets a precedent for protecting employees in AI-driven environments, reinforcing Germany’s leadership in ethical AI governance and supporting a human-centered approach to digital transformation.",
        "Type": "Germany"
      },
      {
        "Date": "2023",
        "Event": "AI Action Plan 2023",
        "Description": "In 2023, Germany released its AI Action Plan, building on the 2018 National AI Strategy to focus on practical AI implementation while balancing regulation and innovation. The plan aims to maintain Germany’s global AI leadership by fostering responsible and competitive AI development. It emphasizes five key areas: creating a risk-based regulatory framework to protect societal values without stifling innovation, supporting AI research and commercialization through funding and collaborations, embedding ethical standards based on the 2019 Data Ethics Commission guidelines, prioritizing sector-specific applications in healthcare, environment, and mobility (e.g., Data Space Mobility Germany), and strengthening international cooperation to align with global AI standards. The plan supports continued investment in AI research centres, start-ups, and industry-academia partnerships, ensuring Germany remains at the forefront of AI technology. It promotes transparency, fairness, and privacy in AI systems, addressing risks like bias and data misuse. By identifying high-impact sectors, the plan drives economic and societal benefits, such as improved healthcare diagnostics and sustainable mobility solutions. International engagement, including participation in global AI initiatives, ensures Germany’s policies align with frameworks like the EU’s AI Act. The AI Action Plan reflects Germany’s commitment to translating strategic vision into actionable steps, fostering an AI ecosystem that benefits society while addressing ethical and regulatory challenges, positioning Germany as a model for responsible AI governance.",
        "Type": "Germany"
      },
      {
        "Date": "September 2021",
        "Event": "National AI Strategy",
        "Description": "The UK's National AI Strategy, launched in September 2021, aims to establish the UK as a global leader in artificial intelligence by 2030. It builds on the UK's strengths in AI research and investment, with the UK ranking third in global academic journal citations and attracting more AI investment than France and Germany combined in 2021. The strategy focuses on enhancing resilience, productivity, and innovation across sectors. Key initiatives include significant funding (over £2.3 billion since 2014), talent attraction through visa reforms, and ethical AI development. It emphasizes international cooperation, participation in global standards organizations, and the publication of open government datasets for AI. The strategy is supported by the Office for Artificial Intelligence and the Centre for Data Ethics and Innovation, ensuring a coordinated approach to AI governance and innovation. It reflects the UK's commitment to harnessing AI's potential while addressing ethical and societal challenges, positioning the UK as a leader in responsible AI development.",
        "Type": "UK"
      },
      {
        "Date": "March 2023",
        "Event": "AI regulation: a pro-innovation approach",
        "Description": "In March 2023, the UK government published its white paper on AI regulation, proposing a pro-innovation approach based on five principles: safety, transparency, fairness, accountability, and contestability. The framework aims to foster innovation while ensuring ethical and responsible AI use. It emphasizes a flexible, proportionate regulatory approach that adapts to AI's rapid evolution. The white paper highlights the need for collaboration between regulators, industry, and academia to develop effective AI governance. A consultation followed, closing in June 2023, with the government response in February 2024 providing implementation details. This policy sets the foundation for the UK's AI regulation, balancing innovation with risk mitigation and ethical considerations. It addresses biases, transparency, data protection, and employment impacts, reflecting a comprehensive approach to AI governance while maintaining a pro-innovation stance.",
        "Type": "UK"
      },
      {
        "Date": "February 2024",
        "Event": "A pro-innovation approach to AI regulation: government response",
        "Description": "In February 2024, the UK government published its response to the AI regulation consultation, detailing the implementation of the five core principles: safety, transparency, fairness, accountability, and contestability. Existing regulators will apply these principles within their domains, supported by guidance and tools like regulatory sandboxes. The response emphasizes international collaboration, with the UK participating in global AI forums like GPAI and the OECD. It also commits to investing in responsible AI research and development. This policy builds on the 2023 white paper, providing a roadmap for AI regulation that supports innovation while protecting public interests. It addresses AI oversight, verification systems, and global standards, ensuring the UK's approach is adaptable and aligned with international efforts to combat misinformation and establish ethical AI practices.",
        "Type": "UK"
      },
      {
        "Date": "January 2025",
        "Event": "AI Opportunities Action Plan: Government Response",
        "Description": "The AI Opportunities Action Plan, published in January 2025, outlines the UK's strategy to become an AI superpower by 2030. It focuses on three pillars: laying foundations for AI infrastructure, adopting AI in public services, and securing sovereign AI capabilities. Key initiatives include expanding AI Research Resources, establishing AI Growth Zones, and launching a National Data Library with privacy safeguards. The plan promotes AI adoption in sectors like healthcare and education through a \"Scan, Pilot, Scale\" approach and supports national champions in AI technology. It includes timelines for deliverables, such as a long-term compute strategy by Spring 2025 and an AI scholarship program by Autumn 2026. This action plan reflects the UK's commitment to leveraging AI for economic growth, public service improvement, and national security, while ensuring ethical development and positioning the UK as a global AI leader.",
        "Type": "UK"
      },
      {
        "Date": "January 2017",
        "Event": "AI Grand Strategy for a Small Country",
        "Description": "Taiwan's AI Grand Strategy for a Small Country, implemented from 2017 to 2021 with a budget of US$517.5 million, aimed to establish Taiwan as a key player in the global AI landscape. Leveraging its strengths in semiconductors and ICT, the strategy focused on building a robust AI ecosystem, establishing dedicated R&D centers, and enhancing AI infrastructure, particularly data centers. It emphasized improving AI chip-making capabilities and organized AI competitions to stimulate innovation. By targeting niche markets like the internet of things, security solutions, and driverless vehicles, Taiwan sought to drive economic growth and maintain competitiveness in the tech industry. The strategy's success laid the foundation for subsequent AI initiatives, fostering talent development and innovation hubs that positioned Taiwan as a leader in AI applications across sectors.",
        "Type": "Taiwan"
      },
      {
        "Date": "January 2018",
        "Event": "AI Taiwan Action Plan 1.0",
        "Description": "Launched on January 18, 2018, the AI Taiwan Action Plan 1.0 aimed to transform Taiwan into a smart nation by 2021. It focused on five components: developing AI talent (training over 10,000 technicians annually), leveraging Taiwan's semiconductor industry for AI computing, building an AI innovation hub, liberalizing laws (e.g., Unmanned Vehicles Technology Innovative Experimentation Act), and transforming industries with AI. The plan promoted deregulation, open access, and technology investment, driving innovation and digital transformation. It positioned Taiwan as a global leader in AI by fostering collaboration between government, industry, and academia, ensuring the nation remained competitive in the evolving tech landscape.",
        "Type": "Taiwan"
      },
      {
        "Date": "2023",
        "Event": "AI Taiwan Action Plan 2.0",
        "Description": "The AI Taiwan Action Plan 2.0, introduced in 2023, builds on the first plan, focusing on ethical standards and governance through 2026. It aims for comprehensive AI regulations by 2024, ensuring responsible development. The plan supports industry intelligentization, R&D in AI technologies, and infrastructure expansion, including supercomputers and AI models like YOLOv4. It strengthens Taiwan's global position by promoting ethical AI aligned with international standards. The Taiwan AI Academy and AI Foundation, established earlier, continue to nurture talent and foster collaboration. By balancing innovation with ethics, the plan positions Taiwan as a model for responsible AI development, maximizing benefits while mitigating risks.",
        "Type": "Taiwan"
      },
      {
        "Date": "2024",
        "Event": "Draft AI Basic Act",
        "Description": "The Draft AI Basic Act, introduced in late 2024 and under review as of June 2025, is a legislative effort to provide a legal foundation for AI development and governance. It defines AI comprehensively and sets principles like sustainability, privacy, and fairness, aligning with global standards (e.g., OECD, EU AI Act). The act adopts a risk-based approach, with the Ministry of Digital Affairs classifying risks and sector-specific regulators enforcing compliance. It emphasizes data privacy while promoting high-quality, non-sensitive data access for AI development. The legislation involves cross-agency collaboration and is designed to be adaptive, addressing AI's impact on areas like labor and the environment. Once enacted, it will be a cornerstone of Taiwan's AI policy, ensuring ethical and sustainable AI growth.",
        "Type": "Taiwan"
      }
  ]